{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_prepr_batches.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShykerBogdan/Prozzoro_project/blob/master/Data_prepr_batches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W5S7eeND767h",
        "colab_type": "code",
        "outputId": "013d184b-bf32-41ba-ca96-1f30cdb886c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m3ND2hmY8G2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OGtgX86K8G-O",
        "colab_type": "code",
        "outputId": "cbe7c52c-a26d-4185-df35-c486f11f67be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "filename='/content/gdrive/My Drive/ML_proz/data_source.csv'\n",
        "df=pd.read_csv(filename)\n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,5,14,15,16,17,18,20,24,38,48,50,51,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3507778, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "rV519cAq8HTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataPreproccessing:\n",
        "    def __init__(self, data_source, churn_interval, start_period=None, end_period=None):\n",
        "        if start_period:\n",
        "          data_source=data_source[pd.to_datetime(data_source['date_from_id'])>start_period]\n",
        "        self.last_day = pd.to_datetime('2018-11-29')\n",
        "        # для статистики постачальника вибираємо проміжок [start_period,end_period]\n",
        "        self.divide_data = self.last_day - pd.DateOffset(days=churn_interval)\n",
        "        print(self.divide_data)\n",
        "        self.data_source = data_source[pd.to_datetime(data_source['date_from_id']) <= self.divide_data]\n",
        "        # для labeling вибираємо період [end_period, end_period+churn_interval]\n",
        "        self.label_data = data_source[pd.to_datetime(data_source['date_from_id']) > self.divide_data]\n",
        "        # вибираємо унікальних постачальників\n",
        "        self.unique_id = list(self.data_source['participants'].value_counts().index)\n",
        "        # створюємо dataframe з колонкою унікальних постачальників і туди будемо додавати features\n",
        "        self.feature_data = pd.DataFrame(self.unique_id, columns=['unique_id'])\n",
        "\n",
        "    def activity_date(self):\n",
        "        f = ['winner', 'tenders.auctionPeriod_startDate', 'contracts.dateSigned', 'date_from_id', 'awards.date']\n",
        "        self.data_source['new_date'] = self.data_source[f].apply(\n",
        "            lambda x: x[f[2]] if x[f[0] == 1] else (x[f[3]] if pd.isnull(x[f[1]]) else x[f[1]]), axis=1)\n",
        "        self.data_source['new_date'] = self.data_source[['new_date']].apply(lambda x: x['new_date'][:10], axis=1)\n",
        "        self.data_source['new_date'] = self.data_source[['new_date', 'date_from_id']].apply(\n",
        "            lambda x: x['date_from_id'] if x['new_date'] == '\\\\N' else x['new_date'], axis=1)\n",
        "\n",
        "    def cleaning(self):\n",
        "        self.data_source['winner'] = self.data_source[['contracts.value_amount', 'contracts.status', 'winner']].apply \\\n",
        "            (lambda x: 0 if x['contracts.value_amount'] == '\\\\N'\n",
        "                            or x['contracts.status'] == 'cancelled' else x['winner'], axis=1)\n",
        "        print('winner updated')\n",
        "        self.activity_date()\n",
        "        print('activity date')\n",
        "\n",
        "#         def convert_to_float(raw):\n",
        "#             try:\n",
        "#                 raw['lots.value_amount'] = float(raw['lots.value_amount'])\n",
        "#             except:\n",
        "#                 raw['lots.value_amount'] = np.nan\n",
        "#             return raw\n",
        "\n",
        "#         self.data_source['lots.value_amount'] = self.data_source[['lots.value_amount']].apply(convert_to_float, axis=1)\n",
        "#         print('convert lots')\n",
        "\n",
        "    def split_into_batches(self, n=20000, filename=None):\n",
        "        self.cleaning()\n",
        "        feature_batches = list()\n",
        "\n",
        "        n_iter = int(np.ceil(self.feature_data.shape[0] / n))\n",
        "        for i in range(n_iter):\n",
        "            print('Batch {0}-{1}:'.format(i * n, (i + 1) * n))\n",
        "            unique_id = self.feature_data.iloc[i * n:(i + 1) * n]['unique_id'].values\n",
        "            feature_df = pd.DataFrame(unique_id, columns=['unique_id'])\n",
        "            feature_batches.append(feature_df)\n",
        "            # part of data_source\n",
        "            df_ = self.data_source.loc[self.data_source['participants'].isin(unique_id)]\n",
        "            print('Unique_supp:{0}-{1}'.format(len(unique_id), df_.shape[0]))\n",
        "            df_ = df_.sort_values(by='new_date')\n",
        "            self.divide_data = str(self.divide_data)[:10]\n",
        "\n",
        "            # features:\n",
        "            # 0. First activity\n",
        "            # 1. Last activity\n",
        "            def get_last_activity(raw, data):\n",
        "                dates=data[data['participants'] == raw['unique_id']]['new_date'].values\n",
        "                raw['last_activity_date'] = dates[-1]\n",
        "                try:\n",
        "                    raw['first_activity_days'] = (\n",
        "                        pd.to_datetime(self.divide_data) - pd.to_datetime(dates[0])).days\n",
        "                    raw['last_activity_days'] = (\n",
        "                        pd.to_datetime(self.divide_data) - pd.to_datetime(raw['last_activity_date'])).days\n",
        "                except:\n",
        "                    print('--------------')\n",
        "                    raw['last_activity_days'] = '?'\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(get_last_activity, args=(df_[['participants','new_date']],),\n",
        "                                                          axis=1)\n",
        "            feature_batches[i]['last_activity_days'] = feature_batches[i].apply(\n",
        "                lambda x: 0 if x['last_activity_days'] < 0 else x['last_activity_days'], axis=1)\n",
        "\n",
        "            # 2. Average activity\n",
        "#             def get_average_activity(raw, data):\n",
        "#                 dates_ = list(data[data['participants'] == raw['unique_id']]['new_date'].values)\n",
        "#                 try:\n",
        "#                     raw['average_activity'] = (pd.to_datetime(dates_[-1]) - pd.to_datetime(dates_[0])).days / len(dates_)\n",
        "#                 except:\n",
        "#                     raw['average_activity'] = np.nan\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(get_average_activity, args=(df_[['participants','new_date']],),\n",
        "#                                                           axis=1)\n",
        "\n",
        "            # 3. Count lots\n",
        "            freq = df_['participants'].value_counts()\n",
        "\n",
        "            def count_lots(raw, frequency):\n",
        "                raw['count_lots'] = frequency[raw['unique_id']]\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(count_lots, args=(freq,), axis=1)\n",
        "\n",
        "#             # 4. Win, lose\n",
        "#             frequency = df_[df_['winner'] == 1]['participants'].value_counts()\n",
        "\n",
        "#             def win_lose(raw, frequency):\n",
        "#                 # use try bsc if index not in frequency 'win'=0\n",
        "#                 try:\n",
        "#                     raw['win'] = frequency[raw['unique_id']]\n",
        "#                 except:\n",
        "#                     raw['win'] = 0\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(win_lose, args=(\n",
        "#                 frequency,), axis=1)\n",
        "#             feature_batches[i]['lose'] = feature_batches[i]['count_lots'] - feature_batches[i]['win']\n",
        "            # 5. Count win open\n",
        "\n",
        "#             frequency = df_.loc[(df_['winner'] == 1) & (df_['tenders.procurementMethod'] == 'open')][\n",
        "#                 'participants'].value_counts()\n",
        "\n",
        "#             def count_win_open(raw, frequency):\n",
        "#                 try:\n",
        "#                     raw['win_open'] = frequency[raw['unique_id']]\n",
        "#                 except:\n",
        "#                     raw['win_open'] = 0\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(count_win_open, args=(\n",
        "#                 frequency,), axis=1)\n",
        "#             feature_batches[i]['win_not_open'] = feature_batches[i]['win'] - feature_batches[i]['win_open']\n",
        "            # 6. Count lose open\n",
        "#             frequency = df_.loc[(df_['winner'] == 0) & (df_['tenders.procurementMethod'] == 'open')][\n",
        "#                 'participants'].value_counts()\n",
        "\n",
        "#             def count_lose_open(raw, frequency):\n",
        "#                 try:\n",
        "#                     raw['lose_open'] = frequency[raw['unique_id']]\n",
        "#                 except:\n",
        "#                     raw['lose_open'] = 0\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(count_lose_open, args=(\n",
        "#                 frequency,), axis=1)\n",
        "#             feature_batches[i]['lose_not_open'] = feature_batches[i]['lose'] - feature_batches[i]['lose_open']\n",
        "            # 7. Average economy\n",
        "#             data = df_[df_['winner'] == 1][\n",
        "#                 ['participants', 'awards.value_amount', 'lots.value_amount']]\n",
        "#             data['economy_value'] = data['lots.value_amount'] - data['awards.value_amount']\n",
        "#             data['economy_percent'] = data['awards.value_amount'] / data['lots.value_amount']\n",
        "\n",
        "#             def get_economy(raw, data):\n",
        "#                 d = data[data['participants'] == raw['unique_id']]\n",
        "#                 raw['economy_value'] = np.nanmean(d['economy_value'])\n",
        "#                 raw['economy_percent'] = np.nanmean(d['economy_percent'])\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(get_economy, args=(data,), axis=1)\n",
        "#             8. Get label\n",
        "#             participants = list(self.label_data['participants'].value_counts().index)\n",
        "\n",
        "#             def get_y(raw, participants):\n",
        "#               if raw['unique_id'] in participants:\n",
        "#                   raw['y'] = 1\n",
        "#               else:\n",
        "#                   raw['y'] = 0\n",
        "#               return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(get_y, args=(participants,), axis=1)\n",
        "            def favourite_percent(raw, data, eps = 0.7):\n",
        "                d = data[data['participants']==raw['unique_id']].drop_duplicates('tenders.id')\n",
        "                try:\n",
        "                  if d['tenders.procuringEntity_identifier_id'].value_counts().iloc[0]/d.shape[0] >=eps:\n",
        "                    raw['favourite_host']=1\n",
        "                  else:\n",
        "                    raw['favourite_host']=0\n",
        "                    raw['count_unique_hosts']=d['tenders.procuringEntity_identifier_id'].value_counts().shape[0]\n",
        "                except:\n",
        "                  raw['favourite_host']=np.nan\n",
        "                  raw['count_unique_hosts']=np.nan\n",
        "                del d\n",
        "                return raw\n",
        "            feature_batches[i] = feature_batches[i].apply(favourite_percent, args=(df_[['participants', 'tenders.id', 'tenders.procuringEntity_identifier_id']],0.75,), axis=1)\n",
        "        if filename:\n",
        "            print(f'write to csv')\n",
        "            feature_batches[i].to_csv(filename + '{0}'.format(i) + '.csv', index=False)\n",
        "\n",
        "        # concat dataframes into one\n",
        "        print('Concat')\n",
        "        all_batches_df = pd.concat(feature_batches)\n",
        "        self.feature_data = all_batches_df.copy()\n",
        "        if filename:\n",
        "            print('write to csv_all')\n",
        "            all_batches_df.to_csv(filename + '_all.csv', index=False)\n",
        "\n",
        "    def get_label(self):\n",
        "        participants = list(self.label_data['participants'].value_counts().index)\n",
        "\n",
        "        def get_y(raw, participants):\n",
        "            if raw['unique_id'] in participants:\n",
        "                raw['y'] = 1\n",
        "            else:\n",
        "                raw['y'] = 0\n",
        "            return raw\n",
        "\n",
        "        self.feature_data = self.feature_data.apply(get_y, args=(participants,), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1ABSfek9iKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "col=['winner','tenders.auctionPeriod_startDate','contracts.dateSigned',\n",
        "     'awards.date','participants','date_from_id','contracts.value_amount','contracts.status']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oTuLbGYs9iJc",
        "colab_type": "code",
        "outputId": "03fde983-f05b-439a-8369-d61cef44c4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        }
      },
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "df1=df[col]\n",
        "prepr = DataPreproccessing(df1.iloc[:10000],1)\n",
        "prepr.split_into_batches(n=1000)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(prepr.feature_data.head())\n",
        "# 158 sec - 30000"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-28 00:00:00\n",
            "winner updated\n",
            "activity date\n",
            "Batch 0-1000:\n",
            "Unique_supp:1000-3304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2f2f93d35a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprepr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataPreproccessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprepr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_into_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-3f451592e8cb>\u001b[0m in \u001b[0;36msplit_into_batches\u001b[0;34m(self, n, filename)\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mfeature_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfavourite_percent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'participants'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tenders.id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tenders.procuringEntity_identifier_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'write to csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['tenders.id' 'tenders.procuringEntity_identifier_id'] not in index\""
          ]
        }
      ]
    }
  ]
}