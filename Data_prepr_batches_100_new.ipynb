{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_prepr_batches_100_new.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShykerBogdan/Prozzoro_project/blob/master/Data_prepr_batches_100_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "W5S7eeND767h",
        "colab_type": "code",
        "outputId": "513e6301-d85b-4744-81b5-2a3819671fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m3ND2hmY8G2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OGtgX86K8G-O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename='/content/gdrive/My Drive/ML_proz/data_source_cleaned.csv'\n",
        "df=pd.read_csv(filename)\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yO3VzGOFveKf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cpv=pd.read_csv('/content/gdrive/My Drive/ML_proz/cpv (2).csv')\n",
        "cpv.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ndwikCJ_t-PV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df=pd.merge(df,cpv,left_on='tenders.id',right_on='tender_id',how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwZ4sgQBUFmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "c92dd8d5-f9da-438d-f141-4a774545f51f"
      },
      "cell_type": "code",
      "source": [
        "df['common_name']=df.apply(lambda raw: raw['tenderers_name'] if pd.notnull(raw['tenderers_name']) else (raw['awards.suppliers_identifier_legalName'] if raw['awards.suppliers_identifier_legalName']!='\\\\N' else raw['awards.suppliers_name']),axis=1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1d442d1ed744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'common_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tenderers_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tenderers_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'awards.suppliers_identifier_legalName'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'awards.suppliers_identifier_legalName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'\\\\N'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'awards.suppliers_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zz-O7GXr0HpR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "a495815f-fbc9-4c0a-dc6c-d98a95de3477"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['awards.bid_id', 'awards.count_documents', 'awards.date', 'awards.id',\n",
              "       'awards.status', 'awards.suppliers_identifier_id',\n",
              "       'awards.suppliers_identifier_legalName', 'awards.suppliers_name',\n",
              "       'awards.value_amount', 'contracts.awardID', 'contracts.date',\n",
              "       'contracts.dateSigned', 'contracts.id', 'contracts.status',\n",
              "       'contracts.value_amount', 'lots.auctionPeriod_startDate',\n",
              "       'lots.guarantee_amount', 'lots.guarantee_currency', 'lots.id',\n",
              "       'lots.status', 'lots.value_amount', 'lots.value_valueAddedTaxIncluded',\n",
              "       'tender_id_x', 'tenderers_address_postalCode',\n",
              "       'tenderers_identifier_id', 'tenderers_name',\n",
              "       'tenders.auctionPeriod_startDate', 'tenders.awardCriteria',\n",
              "       'tenders.awardPeriod_startDate', 'tenders.complaintPeriod_endDate',\n",
              "       'tenders.complaintPeriod_startDate', 'tenders.enquiryPeriod_endDate',\n",
              "       'tenders.enquiryPeriod_startDate', 'tenders.guarantee_amount',\n",
              "       'tenders.id', 'tenders.owner', 'tenders.procurementMethod',\n",
              "       'tenders.procurementMethodType',\n",
              "       'tenders.procuringEntity_address_postalCode',\n",
              "       'tenders.procuringEntity_identifier_id',\n",
              "       'tenders.procuringEntity_identifier_legalName',\n",
              "       'tenders.procuringEntity_identifier_scheme',\n",
              "       'tenders.procuringEntity_name', 'tenders.status',\n",
              "       'tenders.submissionMethod', 'tenders.tenderID',\n",
              "       'tenders.tenderPeriod_endDate', 'tenders.tenderPeriod_startDate',\n",
              "       'tenders.value_amount', 'tenders.value_currency',\n",
              "       'tenders.value_valueAddedTaxIncluded', 'value_amount', 'value_currency',\n",
              "       'participants', 'winner', 'date_from_id', 'new_date', 'Unnamed: 0',\n",
              "       'tender_id_y', 'cpv2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "metadata": {
        "id": "rV519cAq8HTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataPreproccessing:\n",
        "    def __init__(self, data_source, churn_interval=90, start_period=None, end_period=None,start_data_unique=None):\n",
        "       \n",
        "        data_source=data_source[pd.to_datetime(data_source['new_date'])>=start_period]\n",
        "        data_source=data_source[pd.to_datetime(data_source['new_date'])<end_period]\n",
        "        self.start_period=start_period\n",
        "        self.end_period=end_period\n",
        "        self.start_data_unique=start_data_unique\n",
        "        self.last_day = pd.to_datetime('2018-11-29')\n",
        "        self.divide_data = pd.to_datetime(self.end_period) - pd.DateOffset(days=churn_interval)\n",
        "        print(self.divide_data)\n",
        "        self.data_source = data_source[pd.to_datetime(data_source['new_date']) < self.divide_data]\n",
        "        \n",
        "        self.label_data = data_source[pd.to_datetime(data_source['new_date']) >= self.divide_data]\n",
        "        # вибираємо унікальних постачальників\n",
        "#         self.unique_id_data=self.data_source[(pd.to_datetime(self.data_source['new_date'])>=self.start_data_unique) & (pd.to_datetime(self.data_source['new_date'])<=self.divide_data)]\n",
        "        self.unique_data=self.data_source[pd.to_datetime(self.data_source['new_date'])>=self.start_data_unique]\n",
        "        self.unique_data=self.unique_data[pd.to_datetime(self.unique_data['new_date'])<self.divide_data]\n",
        "        self.unique_id = list(self.unique_data['participants'].value_counts().index)\n",
        "        # створюємо dataframe з колонкою унікальних постачальників і туди будемо додавати features\n",
        "        self.feature_data = pd.DataFrame(self.unique_id, columns=['unique_id'])\n",
        "        \n",
        "    def print_dates(self):\n",
        "        print('{0}:'.format((pd.to_datetime(self.divide_data)-pd.to_datetime(self.start_data_unique)).days))\n",
        "        print('{0}:'.format((pd.to_datetime(self.end_period)-pd.to_datetime(self.start_data_unique)).days))\n",
        "        print('Features: [{0}/{1})'.format(self.start_period,self.divide_data))\n",
        "        print('Unique_id: [{0}/{1})'.format(self.start_data_unique,self.divide_data))\n",
        "        print('Labeling: [{0}/{1}]'.format(self.divide_data,self.end_period))\n",
        "    \n",
        "    \n",
        "    \n",
        "    def cleaning(self):\n",
        "        \n",
        "        self.data_source['tenders.procuringEntity_address_postalCode']=self.data_source['tenders.procuringEntity_address_postalCode'].astype(str).str[:2]\n",
        "        self.data_source['tenderers_address_postalCode']=self.data_source['tenderers_address_postalCode'].astype(str).str[:2]\n",
        "        table_postal_code={'Київ':['01', '02', '03', '04', '05', '06'],\n",
        "                  'Київська область':['07', '08', '09'],\n",
        "                  'Житомирська область':['10', '11', '12', '13'],\n",
        "                  'Черніговська область':['14', '15', '16', '17'],\n",
        "                  'Черкаська область':['18', '19', '20'],\n",
        "                  'Вінницька область':['21', '22', '23', '24'],\n",
        "                  'Кіровоградська область':['25', '26', '27', '28'],\n",
        "                  'Хмельницька область':['29', '30', '31', '32'],\n",
        "                  'Рівненська область': ['33', '34', '35'],\n",
        "                  'Полтавська область':['36', '37', '38', '39'],\n",
        "                  'Сумська область':['40', '41', '42'],\n",
        "                  'Волинська область':['43', '44', '45'],\n",
        "                  'Тернопольська область':['46', '47', '48'],\n",
        "                  'Дніпропетровська область':['49', '50', '51', '52', '53'],\n",
        "                  'Миколаївська область':['54', '55', '56', '57'],\n",
        "                  'Чернівецька область':['58', '59', '60'],\n",
        "                  'Харьківська область':['61', '62', '63', '64'],\n",
        "                  'Одеська область':['65', '66', '67', '68'],\n",
        "                  'Запоріжська область':['69', '70', '71', '72'],\n",
        "                  'Херсонська область':['73', '74', '75'],\n",
        "                  'Івано-Франківська область':['76', '77', '78'],\n",
        "                  'Львівська область':['79', '80', '81', '82'],\n",
        "                  'Донецька область':['83', '84', '85', '86', '87'],\n",
        "                  'Закарпатська область':['88', '89', '90'],\n",
        "                  'Луганська область':['91', '92', '93', '94'],\n",
        "                  'Автономна республіка Крим':['95', '96', '97', '98'],\n",
        "                  'Севастопіль':['99']}\n",
        "        regions=dict()\n",
        "        for key,value in table_postal_code.items():\n",
        "            for item in value:\n",
        "              regions[item]=key\n",
        "        def get_region(raw,regions):\n",
        "            try:\n",
        "              raw['region']=regions[raw['tenders.procuringEntity_address_postalCode']]\n",
        "            except:  \n",
        "              raw['region']=np.nan\n",
        "            return raw\n",
        "        self.data_source=self.data_source.apply(get_region,args=(regions,),axis=1)\n",
        "        def get_region_supp(raw,regions):\n",
        "            try:\n",
        "              raw['region_supp']=regions[raw['tenderers_address_postalCode']]\n",
        "            except:  \n",
        "              raw['region_supp']=np.nan\n",
        "            return raw\n",
        "        self.data_source=self.data_source.apply(get_region_supp,args=(regions,),axis=1)\n",
        "        print('regions updated')\n",
        "        \n",
        "    def split_into_batches(self, n=20000, filename=None):\n",
        "        \n",
        "        self.cleaning()\n",
        "        feature_batches = list()\n",
        "        n_iter = int(np.ceil(self.feature_data.shape[0] / n))\n",
        "        for i in range(n_iter):\n",
        "            start_time = time.time()\n",
        "            print('Batch {0}-{1}:'.format(i * n, (i + 1) * n))\n",
        "            unique_id = self.feature_data.iloc[i * n:(i + 1) * n]['unique_id'].values\n",
        "            feature_df = pd.DataFrame(unique_id, columns=['unique_id'])\n",
        "            feature_batches.append(feature_df)\n",
        "            # part of data_source\n",
        "            df_ = self.data_source.loc[self.data_source['participants'].isin(unique_id)]\n",
        "            print('Unique_supp:{0}-{1}'.format(len(unique_id), df_.shape[0]))\n",
        "            df_ = df_.sort_values(by='new_date')\n",
        "            self.divide_data = str(self.divide_data)[:10]\n",
        "\n",
        "            # features:\n",
        "            def get_most_common_name(raw,df):\n",
        "                data=df[df['participants']==raw['unique_id']][['awards.suppliers_identifier_legalName','tenderers_name','awards.suppliers_name']]\n",
        "                data['common_name']=data.apply(lambda raw: raw['tenderers_name'] if pd.notnull(raw['tenderers_name']) else (raw['awards.suppliers_identifier_legalName'] if raw['awards.suppliers_identifier_legalName']!='\\\\N' else raw['awards.suppliers_name']),axis=1)\n",
        "                \n",
        "#                 z=list(data['common_name'].values)\n",
        "#                 d=dict()\n",
        "#                 for item in z:\n",
        "#                   if item not in d.keys():\n",
        "#                     d[item]=z.count(item)\n",
        "#                 max_=0\n",
        "#                 max_name=''\n",
        "#                 for key,value in d.items():\n",
        "#                   if value>max_:\n",
        "#                     max_=value\n",
        "#                     max_name=key\n",
        "#                 raw['common_name']=max_name\n",
        "                return raw\n",
        "            feature_batches[i] = feature_batches[i].apply(get_most_common_name, args=(df_[['participants','awards.suppliers_identifier_legalName','tenderers_name','awards.suppliers_name']],),axis=1)\n",
        "            # 0. First activity\n",
        "            # 1. Last activity\n",
        "            def get_last_activity(raw, data,eps=0.7):\n",
        "                date=data[data['participants'] == raw['unique_id']]\n",
        "                dates=date['new_date'].values\n",
        "                # favourite host\n",
        "                try:\n",
        "                  if date['tenders.procuringEntity_identifier_id'].value_counts().iloc[0]/date.shape[0] >=eps:\n",
        "                    raw['favourite_host']=1\n",
        "                  else:\n",
        "                    raw['favourite_host']=0\n",
        "                  raw['count_unique_hosts']=date['tenders.procuringEntity_identifier_id'].value_counts().shape[0]\n",
        "                except:\n",
        "                  raw['favourite_host']=np.nan\n",
        "                  raw['count_unique_hosts']=np.nan\n",
        "                # name\n",
        "                raw['common_name']=list(date['common_name'].value_counts().index())[0]\n",
        "                # get cpv\n",
        "                raw['cpv']=','.join([str(item) for item in set(date['cpv2'].values)])\n",
        "                # unique_region\n",
        "                raw['unique_regions']=len(set(date['region'].values))\n",
        "                # get supp region \n",
        "                for code in date['region_supp'].values:\n",
        "                  if pd.notnull(code):\n",
        "                    raw['supp_region']=code\n",
        "#                 raw['last_activity_date'] = dates[-1]\n",
        "                try:\n",
        "                    raw['first_activity_days'] = (\n",
        "                        pd.to_datetime(self.divide_data) - pd.to_datetime(dates[0])).days\n",
        "                    raw['last_activity_days'] = (\n",
        "                        pd.to_datetime(self.divide_data) - pd.to_datetime(dates[-1])).days\n",
        "                    if len(dates)!=1:\n",
        "                      raw['average_activity']=(pd.to_datetime(dates[-1])-pd.to_datetime(dates[0])).days/(len(dates)-1)\n",
        "                    else:\n",
        "                      raw['average_activity']='?'\n",
        "                except:\n",
        "                    print('--------------')\n",
        "                    raw['average_activity'] = '?'\n",
        "                    \n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(get_last_activity, args=(df_[['cpv2','participants','new_date','tenders.procuringEntity_identifier_id','tenders.id','region','region_supp']],0.75,),\n",
        "                                                          axis=1)\n",
        "            feature_batches[i]['last_activity_days'] = feature_batches[i].apply(\n",
        "                lambda x: 0 if x['last_activity_days'] < 0 else x['last_activity_days'], axis=1)\n",
        "            print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "            # 2. Average activity\n",
        "#             def get_average_activity(raw, data):\n",
        "#                 dates_ = list(data[data['participants'] == raw['unique_id']]['new_date'].values)\n",
        "#                 try:\n",
        "#                     raw['average_activity'] = (pd.to_datetime(dates_[-1]) - pd.to_datetime(dates_[0])).days / len(dates_)\n",
        "#                 except:\n",
        "#                     raw['average_activity'] = np.nan\n",
        "#                 return raw\n",
        "\n",
        "#             feature_batches[i] = feature_batches[i].apply(get_average_activity, args=(df_[['participants','new_date']],),\n",
        "#                                                           axis=1)\n",
        "\n",
        "            # 3. Count lots\n",
        "            freq = df_['participants'].value_counts()\n",
        "\n",
        "            def count_lots(raw, frequency):\n",
        "                raw['count_lots'] = frequency[raw['unique_id']]\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(count_lots, args=(freq,), axis=1)\n",
        "\n",
        "            # 4. Win, lose\n",
        "            frequency = df_[df_['winner'] == 1]['participants'].value_counts()\n",
        "            print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "            def win_lose(raw, frequency):\n",
        "                # use try bsc if index not in frequency 'win'=0\n",
        "                try:\n",
        "                    raw['win'] = frequency[raw['unique_id']]\n",
        "                except:\n",
        "                    raw['win'] = 0\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(win_lose, args=(\n",
        "                frequency,), axis=1)\n",
        "            feature_batches[i]['lose'] = feature_batches[i]['count_lots'] - feature_batches[i]['win']\n",
        "            print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "#             5. Count win open\n",
        "\n",
        "            frequency = df_.loc[(df_['winner'] == 1) & (df_['tenders.procurementMethod'] == 'open')][\n",
        "                'participants'].value_counts()\n",
        "\n",
        "            def count_win_open(raw, frequency):\n",
        "                try:\n",
        "                    raw['win_open'] = frequency[raw['unique_id']]\n",
        "                except:\n",
        "                    raw['win_open'] = 0\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(count_win_open, args=(\n",
        "                frequency,), axis=1)\n",
        "            feature_batches[i]['win_not_open'] = feature_batches[i]['win'] - feature_batches[i]['win_open']\n",
        "            print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "#             6. Count lose open\n",
        "            frequency = df_.loc[(df_['winner'] == 0) & (df_['tenders.procurementMethod'] == 'open')][\n",
        "                'participants'].value_counts()\n",
        "\n",
        "            def count_lose_open(raw, frequency):\n",
        "                try:\n",
        "                    raw['lose_open'] = frequency[raw['unique_id']]\n",
        "                except:\n",
        "                    raw['lose_open'] = 0\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(count_lose_open, args=(\n",
        "                frequency,), axis=1)\n",
        "#             feature_batches[i]['lose_not_open'] = feature_batches[i]['lose'] - feature_batches[i]['lose_open']\n",
        "            print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "            # 7. Average economy\n",
        "            data = df_[df_['winner'] == 1][\n",
        "                ['participants', 'awards.value_amount', 'lots.value_amount']]\n",
        "            data['economy_value'] = data['lots.value_amount'] - data['awards.value_amount']\n",
        "            data['economy_percent'] = data['awards.value_amount'] / data['lots.value_amount']\n",
        "\n",
        "            def get_economy(raw, data):\n",
        "                d = data[data['participants'] == raw['unique_id']]\n",
        "                raw['economy_value'] = np.nanmean(d['economy_value'])\n",
        "                raw['average_winner_price']=np.nansum(d['awards.value_amount'])/d.shape[0]\n",
        "                raw['economy_percent'] = np.nanmean(d['economy_percent'])\n",
        "                return raw\n",
        "\n",
        "            feature_batches[i] = feature_batches[i].apply(get_economy, args=(data,), axis=1)\n",
        "#             8. Get label\n",
        "            participants = list(self.label_data['participants'].value_counts().index)\n",
        "\n",
        "            def get_y(raw, participants):\n",
        "              if raw['unique_id'] in participants:\n",
        "                  raw['y'] = 1\n",
        "              else:\n",
        "                  raw['y'] = 0\n",
        "              return raw\n",
        "#             9. Get favourite hosts\n",
        "            feature_batches[i] = feature_batches[i].apply(get_y, args=(participants,), axis=1)\n",
        "#             def favourite_percent(raw, data, eps = 0.7):\n",
        "#                 d = data[data['participants']==raw['unique_id']].drop_duplicates('tenders.id')\n",
        "#                 try:\n",
        "#                   if d['tenders.procuringEntity_identifier_id'].value_counts().iloc[0]/d.shape[0] >=eps:\n",
        "#                     raw['favourite_host']=1\n",
        "#                   else:\n",
        "#                     raw['favourite_host']=0\n",
        "#                     raw['count_unique_hosts']=d['tenders.procuringEntity_identifier_id'].value_counts().shape[0]\n",
        "#                 except:\n",
        "#                   raw['favourite_host']=np.nan\n",
        "#                   raw['count_unique_hosts']=np.nan\n",
        "#                 del d\n",
        "#                 return raw\n",
        "#             feature_batches[i] = feature_batches[i].apply(favourite_percent, args=(df_[['participants', 'tenders.id', 'tenders.procuringEntity_identifier_id']],0.75,), axis=1)\n",
        "            # 10. Get unique region\n",
        "            print(\" Batch %s seconds ---\" % (time.time() - start_time))\n",
        "        if filename:\n",
        "            print(f'write to csv')\n",
        "            feature_batches[i].to_csv(filename + '{0}'.format(i) + '.csv', index=False)\n",
        "\n",
        "        \n",
        "        # concat dataframes into one\n",
        "        print('Concat')\n",
        "        all_batches_df = pd.concat(feature_batches)\n",
        "        self.feature_data = all_batches_df.copy()\n",
        "        if filename:\n",
        "            print('write to csv_all')\n",
        "            all_batches_df.to_csv(filename + '_all.csv', index=False)\n",
        "        print(\" --- %s seconds ---\" % (time.time() - start_time))\n",
        "    def get_label(self):\n",
        "        participants = list(self.label_data['participants'].value_counts().index)\n",
        "\n",
        "        def get_y(raw, participants):\n",
        "            if raw['unique_id'] in participants:\n",
        "                raw['y'] = 1\n",
        "            else:\n",
        "                raw['y'] = 0\n",
        "            return raw\n",
        "\n",
        "        self.feature_data = self.feature_data.apply(get_y, args=(participants,), axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y1ABSfek9iKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "col=['winner','tenders.auctionPeriod_startDate','contracts.dateSigned',\n",
        "     'awards.date','participants','date_from_id','contracts.value_amount','tenders.procurementMethod','contracts.status','awards.value_amount','tenders.id','tenders.procuringEntity_identifier_id','lots.value_amount']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nvhVQovVsQHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "492b29d5-a2e4-48b7-c951-bd44bca15e2b"
      },
      "cell_type": "code",
      "source": [
        "prepr = DataPreproccessing(df.iloc[:100000],start_period='2016-09-10',end_period='2017-06-07',start_data_unique='2016-12-09',churn_interval=90)\n",
        "prepr.print_dates()\n",
        "prepr.split_into_batches(n=10000)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2017-03-09 00:00:00\n",
            "90:\n",
            "180:\n",
            "Features: [2016-09-10/2017-03-09 00:00:00)\n",
            "Unique_id: [2016-12-09/2017-03-09 00:00:00)\n",
            "Labeling: [2017-03-09 00:00:00/2017-06-07]\n",
            "regions updated\n",
            "Batch 0-10000:\n",
            "Unique_supp:5742-11117\n",
            " --- 56.10307836532593 seconds ---\n",
            " --- 60.31604194641113 seconds ---\n",
            " --- 64.47673606872559 seconds ---\n",
            " --- 68.877525806427 seconds ---\n",
            " --- 73.13311743736267 seconds ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:238: RuntimeWarning: Mean of empty slice\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:239: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:240: RuntimeWarning: Mean of empty slice\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Batch 106.3998966217041 seconds ---\n",
            "Concat\n",
            " --- 106.40474438667297 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}